\section{Introduction}
\label{sec.introduction}

Privileged code is an essential component of modern computer systems but 
presents a number of security challenges. The privileged code itself is vulnerable 
to attacks and other parts of the system could be damaged when vulnerabilities in 
that privileged code are exploited.

Failures in the trusted computing base (TCB) allow more impactful crashes, 
such as complete system failures, privilege escalation, etc. 
Decreasing the feasibility of exploitation of the kernel bugs, especially privilege escalation, 
would be a substantial step toward stronger security for computer systems.

Bugs in operating system kernels have motivated development of a diverse set of
technologies to attempt to reduce these risks, such as OS virtualization, system
call filtering, library OSes, etc. Unfortunately, these technologies also 
harbor vulnerabilities that are also exploitable. Even with these technologies in place,
applications from the user space could still have access to a portion of the kernel that might contain 
bugs and is risky to be exposed. 

One contributing factor to security problems associated with these existing technologies and potential
new designs is that it is still unknown which portions of the privileged code are
safe to expose, and which portions would be vulnerable and exploitable. 
One key missing puzzle is a standard method for quantifying the safety (or risky) levels of the privileged code. 
For example, is it a good practice to minimize \textit{the number of lines of code}?
Is \textit{the number of API calls} a good metric for security? 
To our best knowledge, there has yet to be quantitative metric to evaluate the privileged code and provide 
insights into how to design a secure system that only interacts with the privileged code in a safe manner.

In this paper, we propose a metric that quantitatively measures and evaluated the 
kernel code. The kernel trace profiling data is an important piece of information 
obtained by using our metric. This data reveals the use pattern of the kernel code 
based upon applications running from the user space. The use pattern can then be
leveraged to design new systems that have to meet specific requirements, 
such as strong security or high performance.

To protect the kernel from being exploited, we came up with a new design 
that aims at providing strong isolation between the kernel space and the user space, 
and thus providing better protection to the kernel. Our new design leverages 
our metric to make better design decisions and build more effective system. 
Based upon our new design, we implemented a sandbox system, called Lind.
Lind minimized the amount of risky privileged code that is executed.  
Risky functionality is itself implemented inside a sandbox with
a small trusted computing base (TCB). 
This additional level of sandboxing provides an outlet for risky functionality, without which
legacy programs will not run, while containing security flaws in this code. 

We evaluate Lind by comparing it against other similar systems 
that are not designed using our metric. More specifically, we run user applications
under Lind and other systems, and compare their kernel traces. In addition, we examined historical
kernel bug reports to verify whose kernel trace is likely to trigger more kernel bugs
Evaluation results showed that running applications in Lind is least likely to trigger kernel bugs, 
which validates that designs, such as the prototype of Lind, which uses our metric, 
will lead to more secure systems. 

The main contributions of this paper are as follows:

\begin{itemize}
\item We propose a novel metric for quantitatively measuring and evaluating the kernel. 
Our metric examines the kernel trace generated by running user applications at the lines-of-code level.  

\item We obtained the kernel trace profiling data by running user applications under Native Linux and 
showed how to use the data to gain insights into different features of the kernel code.

\item We designed a novel secure architecture that came from examining and leveraging our metric. 
Using this new architecture, we implemented a sandbox we called Lind, which provides more secure environment
for running legacy applications and provide strong protection to the kernel. 

\item Our evaluation results showed that implementation of our sandbox Lind only has the potential to 
trigger 2.5\% of zero-day vulnerabilities we examined, 
while systems built without using our metric have more chances to trigger vulnerabilities, which validates 
that our metric can help design and build more secure systems effectively.
\end{itemize}

The remainder of this paper is organized as follows. 
We discuss the motivation that drives our work in \S{2}. 
In \S{3}, we propose our metric as the solution to solve the problem and provide detailed discussion about the metric.
New architecture we designed using our metric is introduced in \S{4}. In \S{5}, we discuss the implementation of the design, a sandbox we called Lind. 
Evaluation results of our Lind system and new design strategy are presented in \S{6}. 
We then discuss related work in \S{7} and conclude in \S{8}. 